{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c4d0740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/shuozhe/miniconda3/envs/xr1/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at /nfs/shuozhe/clean_pretrain/checkpoints/Qwen2.5-0.5B-TinyStories-q_reg_ce_head_only/model_2000 were not used when initializing Qwen2ForCausalLM: {'q_head.weight', 'q_head.bias'}\n",
      "- This IS expected if you are initializing Qwen2ForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Qwen2ForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_311590/711731153.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sd = torch.load(q_head_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Attached q_head: hidden=896, vocab=151665, dtype=torch.bfloat16, device=cuda:0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# --- point this to your saved checkpoint directory ---\n",
    "\n",
    "\n",
    "def pick_dtype():\n",
    "    if torch.cuda.is_available():\n",
    "        if torch.cuda.is_bf16_supported():\n",
    "            return torch.bfloat16\n",
    "        return torch.float16\n",
    "    return torch.float32\n",
    "\n",
    "def load_model_and_q_head(model_dir: str, device: str):\n",
    "    \"\"\"Load base HF model and attach q_head from sidecar q_head.pt if present.\"\"\"\n",
    "    dtype = pick_dtype() if device.startswith(\"cuda\") else torch.float32\n",
    "\n",
    "    tok = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "    if tok.pad_token is None:\n",
    "        tok.pad_token = tok.eos_token\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_dir,\n",
    "        torch_dtype=dtype if device.startswith(\"cuda\") else None,\n",
    "        trust_remote_code=True,\n",
    "    ).to(device).eval()\n",
    "\n",
    "    # Try to attach q_head with correct shapes and dtype/device.\n",
    "    q_head_path = os.path.join(model_dir, \"q_head.pt\")\n",
    "    if os.path.exists(q_head_path):\n",
    "        # infer hidden size from config (robustly)\n",
    "        cfg = getattr(model, \"config\", None)\n",
    "        hidden_size = (\n",
    "            getattr(cfg, \"hidden_size\", None)\n",
    "            or getattr(cfg, \"n_embd\", None)\n",
    "            or getattr(cfg, \"hidden_dim\", None)\n",
    "        )\n",
    "        if hidden_size is None:\n",
    "            raise RuntimeError(\"Could not infer hidden size for q_head from model.config\")\n",
    "\n",
    "        # infer vocab size from output embeddings\n",
    "        out_emb = model.get_output_embeddings()\n",
    "        if hasattr(out_emb, \"num_embeddings\"):\n",
    "            vocab_size = int(out_emb.num_embeddings)\n",
    "        elif hasattr(out_emb, \"out_features\"):\n",
    "            vocab_size = int(out_emb.out_features)\n",
    "        else:\n",
    "            raise RuntimeError(\"Could not infer vocab size from model.get_output_embeddings()\")\n",
    "\n",
    "        # construct head on same device/dtype as model weights\n",
    "        model_dtype = next(model.parameters()).dtype\n",
    "        model_device = next(model.parameters()).device\n",
    "        q_head = nn.Linear(hidden_size, vocab_size, bias=True).to(device=model_device, dtype=model_dtype)\n",
    "\n",
    "        # load sidecar weights\n",
    "        sd = torch.load(q_head_path, map_location=\"cpu\")\n",
    "        q_head.load_state_dict(sd, strict=True)\n",
    "        q_head.to(device=model_device, dtype=model_dtype)\n",
    "\n",
    "        # attach to model\n",
    "        model.q_head = q_head\n",
    "        print(f\"[INFO] Attached q_head: hidden={hidden_size}, vocab={vocab_size}, dtype={model_dtype}, device={model_device}\")\n",
    "    else:\n",
    "        print(\"[WARN] q_head.pt not found; will fall back to using logits as Q if you trained without --use_q_head\")\n",
    "\n",
    "    return tok, model\n",
    "\n",
    "@torch.no_grad()\n",
    "def q_values_for_sequence(model, tok, text: str, device: str):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      q_logits: (1, T, V) tensor = predicted Q(s_t, a) for all tokens at each position\n",
    "      q_taken:  (1, T-1) tensor = Q(s_t, a_t) for the actually-taken next token (labels)\n",
    "      seq_value: scalar = predicted V(s_0) = Q(s_0, a_0) under your training target\n",
    "    Notes:\n",
    "      - We use next-token labeling: action at time t is the token at position t+1.\n",
    "      - If no q_head is present, we interpret base logits as Q (matching your training code).\n",
    "    \"\"\"\n",
    "    enc = tok(text, return_tensors=\"pt\")\n",
    "    input_ids = enc[\"input_ids\"].to(device)\n",
    "    attn = enc[\"attention_mask\"].to(device)\n",
    "\n",
    "    out = model(input_ids=input_ids, attention_mask=attn,\n",
    "                output_hidden_states=True, return_dict=True, use_cache=False)\n",
    "\n",
    "    # If q_head exists, project last hidden; else reuse logits (as in your training code)\n",
    "    if hasattr(model, \"q_head\") and isinstance(model.q_head, nn.Module):\n",
    "        hidden_last = out.hidden_states[-1]            # (1, T, H)\n",
    "        # cast hidden to the head's dtype to avoid bf16/fp16 matmul dtype errors\n",
    "        if hidden_last.dtype != model.q_head.weight.dtype:\n",
    "            hidden_last = hidden_last.to(model.q_head.weight.dtype)\n",
    "        q_logits = model.q_head(hidden_last)           # (1, T, V)\n",
    "    else:\n",
    "        q_logits = out.logits                          # (1, T, V) treated as Q\n",
    "\n",
    "    # Build labels (next-token)\n",
    "    labels = input_ids.clone()\n",
    "    labels[labels == tok.pad_token_id] = -100\n",
    "    # Gather Q(s_t, a_t) for taken actions (shift by one for next-token)\n",
    "    # actions at time t are labels[:, t+1]\n",
    "    if q_logits.size(1) >= 2:\n",
    "        taken = labels[:, 1:]  # (1, T-1)\n",
    "        q_taken = torch.gather(q_logits[:, :-1, :], dim=-1, index=taken.unsqueeze(-1)).squeeze(-1)  # (1, T-1)\n",
    "        seq_value = q_taken[0, 0].item()  # predicted V(s_0)\n",
    "    else:\n",
    "        # Single token edge case\n",
    "        q_taken = torch.empty((1, 0), device=q_logits.device, dtype=q_logits.dtype)\n",
    "        seq_value = float(\"nan\")\n",
    "\n",
    "    return q_logits, q_taken, seq_value\n",
    "\n",
    "def pretty_topk(q_logits, tok, t: int, k: int = 10):\n",
    "    \"\"\"Utility: show top-k actions by Q at position t.\"\"\"\n",
    "    logits_t = q_logits[0, t]  # (V,)\n",
    "    topv, topi = torch.topk(logits_t, k)\n",
    "    toks = tok.convert_ids_to_tokens(topi.tolist())\n",
    "    return list(zip(toks, topv.tolist()))\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "# MODEL_DIR = \"/nfs/shuozhe/clean_pretrain/checkpoints/Qwen2.5-0.5B-TinyStories-q_reg_0.7/model_3000\"\n",
    "MODEL_DIR = \"/nfs/shuozhe/clean_pretrain/checkpoints/Qwen2.5-0.5B-TinyStories-q_reg_ce_head_only/model_2000\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tok, model = load_model_and_q_head(MODEL_DIR, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b26ae1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence: 'Once upon a time, there was a girl'\n",
      "Predicted V(s_0) (i.e., Q(s_0, a_0)): 0.2051\n",
      "\n",
      "Top-10 Q(s_1, a) suggestions:\n",
      "           . : 2.4688\n",
      "           , : 1.6328\n",
      "        Ġand : 1.5391\n",
      "        Ġthe : 1.4844\n",
      "          Ġa : 1.3359\n",
      "         Ġto : 1.2031\n",
      "        Ġwas : 1.0156\n",
      "         .ĊĊ : 0.4805\n",
      "         Ġit : 0.4629\n",
      "        Ġher : 0.4160\n",
      "        ĠShe : 0.4082\n",
      "         ĠHe : 0.4023\n",
      "         Ġin : 0.3691\n",
      "         Ġhe : 0.3242\n",
      "          Ġ\" : 0.3105\n",
      "       Ġsaid : 0.3086\n",
      "        Ġshe : 0.2988\n",
      "       Ġwith : 0.2773\n",
      "        Ġhis : 0.2773\n",
      "        Ġday : 0.2754\n",
      "       ĠThey : 0.2695\n",
      "        Once : 0.2598\n",
      "      Ġthere : 0.2480\n",
      "       Ġtime : 0.2383\n",
      "         Ġso : 0.2334\n",
      "         Ġof : 0.2275\n",
      "        Ġhad : 0.2275\n",
      "       ĠLily : 0.2275\n",
      "       Ġupon : 0.2158\n",
      "       Ġthat : 0.2139\n",
      "     Ġlittle : 0.2129\n",
      "          's : 0.2109\n",
      "       Ġthey : 0.2002\n",
      "         Ġon : 0.1963\n",
      "       Ġvery : 0.1963\n",
      "        ĠThe : 0.1904\n",
      "        Ġsaw : 0.1904\n",
      "        Ġbig : 0.1768\n",
      "       Ġplay : 0.1699\n",
      "         ĠIt : 0.1689\n",
      "        Ġmom : 0.1689\n",
      "        Ġbut : 0.1641\n",
      "       Ġgirl : 0.1641\n",
      "         ĠĊĊ : 0.1592\n",
      "        Ġfor : 0.1582\n",
      "     Ġwanted : 0.1582\n",
      "          my : 0.1494\n",
      "       Ġwere : 0.1475\n",
      "        ĠTim : 0.1465\n",
      "        Ġyou : 0.1455\n",
      "          't : 0.1387\n",
      "        Ġnot : 0.1377\n",
      "         The : 0.1367\n",
      "          ĠI : 0.1299\n",
      "           ! : 0.1270\n",
      "       Ġthem : 0.1245\n",
      "        ĠOne : 0.1221\n",
      "      Ġloved : 0.1152\n",
      "         Ġup : 0.1147\n",
      "      Ġasked : 0.1147\n",
      "         One : 0.1099\n",
      "         Ġat : 0.1089\n",
      "       Ġlike : 0.1089\n",
      "      Ġtheir : 0.1079\n",
      "          !\" : 0.1079\n",
      "        Ġall : 0.1064\n",
      "      Ġnamed : 0.1060\n",
      "           \" : 0.1045\n",
      "       Ġwent : 0.1040\n",
      "         Ġgo : 0.1021\n",
      "      Ġcould : 0.1016\n",
      "     Ġaround : 0.0996\n",
      "      Ġhappy : 0.0996\n",
      "         Ġis : 0.0962\n",
      "        Ġcan : 0.0938\n",
      "        Ġboy : 0.0933\n",
      "        ĠBen : 0.0928\n",
      "       Ġtoys : 0.0884\n",
      "       Ġmake : 0.0835\n",
      "       Ġtake : 0.0820\n",
      "       Ġhave : 0.0806\n",
      "           L : 0.0786\n",
      "         Ġbe : 0.0786\n",
      "           I : 0.0781\n",
      "       Ġsome : 0.0776\n",
      "    Ġfriends : 0.0762\n",
      "        ĠTom : 0.0757\n",
      "        Ġsee : 0.0737\n",
      "     Ġscared : 0.0732\n",
      "        Ġare : 0.0728\n",
      "  Ġsomething : 0.0728\n",
      "      Ġfound : 0.0723\n",
      "         ily : 0.0713\n",
      "        Lens : 0.0713\n",
      "        Ġran : 0.0698\n",
      "         Ġas : 0.0693\n",
      "        ĠBut : 0.0693\n",
      "       Ġwhat : 0.0688\n",
      "        Ġhim : 0.0688\n",
      "    Ġoutside : 0.0688\n",
      "\n",
      "Q(s_t, a_t) along the trajectory:\n",
      "t= 0 : 0.2051 (token='Ġupon')\n",
      "t= 1 : 1.3359 (token='Ġa')\n",
      "t= 2 : 0.2334 (token='Ġtime')\n",
      "t= 3 : 1.6797 (token=',')\n",
      "t= 4 : 0.2695 (token='Ġthere')\n",
      "t= 5 : 1.0000 (token='Ġwas')\n",
      "t= 6 : 1.3281 (token='Ġa')\n",
      "t= 7 : 0.1465 (token='Ġgirl')\n"
     ]
    }
   ],
   "source": [
    "# Example text to score\n",
    "text = \"Once upon a time, there was a girl\"\n",
    "# text = \"Once upon a time, there was a bot\"\n",
    "\n",
    "q_logits, q_taken, seq_value = q_values_for_sequence(model, tok, text, device)\n",
    "print(f\"Sequence: {text!r}\")\n",
    "print(f\"Predicted V(s_0) (i.e., Q(s_0, a_0)): {seq_value:.4f}\")\n",
    "\n",
    "# Inspect a specific position's top-Q actions\n",
    "t = 1\n",
    "top = pretty_topk(q_logits, tok, t=t, k=100)\n",
    "print(f\"\\nTop-10 Q(s_{t}, a) suggestions:\")\n",
    "for tok_str, val in top:\n",
    "    print(f\"{tok_str:>12s} : {val:.4f}\")\n",
    "\n",
    "# Also print Q for the actually taken actions (labels)\n",
    "if q_taken.numel() > 0:\n",
    "    print(\"\\nQ(s_t, a_t) along the trajectory:\")\n",
    "    vals = q_taken[0].tolist()\n",
    "    for i, v in enumerate(vals):\n",
    "        # print index and value and token\n",
    "        print(f\"t={i:2d} : {v:.4f} (token={tok.convert_ids_to_tokens([tok.encode(text, add_special_tokens=False)[i+1]])[0]!r})\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xr1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
