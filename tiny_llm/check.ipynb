{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simple script to load checkpoint and test the model.\n",
    "Allows user to input custom prompts or use dyck_random examples.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from toy_llm import TinyGPT, make_dyck1_random\n",
    "\n",
    "def load_checkpoint(checkpoint_path, device='cpu'):\n",
    "    \"\"\"Load model and metadata from checkpoint.\"\"\"\n",
    "    # print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    cfg = checkpoint['config']\n",
    "    vocab_size = checkpoint['vocab_size']\n",
    "    stoi = checkpoint['stoi']\n",
    "    itos = checkpoint['itos']\n",
    "    iteration = checkpoint['iteration']\n",
    "    \n",
    "    # Create model\n",
    "    model = TinyGPT(\n",
    "        vocab_size=vocab_size,\n",
    "        block_size=cfg.block_size,\n",
    "        n_layer=cfg.n_layer,\n",
    "        n_head=cfg.n_head,\n",
    "        n_embd=cfg.n_embd,\n",
    "        emb_pdrop=0.0,\n",
    "        resid_pdrop=0.0,\n",
    "        attn_pdrop=0.0\n",
    "    ).to(device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    # print(f\"✓ Successfully loaded checkpoint from iteration {iteration}\")\n",
    "    # print(f\"✓ Model config: vocab_size={vocab_size}, block_size={cfg.block_size}\")\n",
    "    # print(f\"  n_layer={cfg.n_layer}, n_head={cfg.n_head}, n_embd={cfg.n_embd}\")\n",
    "    # print(f\"✓ Training objective: {cfg.objective}\\n\")\n",
    "    \n",
    "    return model, stoi, itos, cfg\n",
    "\n",
    "def generate_continuation(model, prompt, stoi, itos, max_new_tokens=150, device='cpu', temperature=1.0):\n",
    "    \"\"\"Generate continuation from a prompt.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Encode prompt\n",
    "    x = torch.tensor([[stoi.get(c, 0) for c in prompt]], dtype=torch.long, device=device)\n",
    "    generated = list(prompt)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Crop to block_size if needed\n",
    "            x_cond = x if x.size(1) <= model.block_size else x[:, -model.block_size:]\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(x_cond)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            \n",
    "            # Sample\n",
    "            ix = torch.multinomial(probs, num_samples=1)\n",
    "            ch = itos[ix.item()]\n",
    "            generated.append(ch)\n",
    "            \n",
    "            # Append to sequence\n",
    "            x = torch.cat([x, ix], dim=1)\n",
    "            \n",
    "            # Stop if we've closed all parens (for paren sequences)\n",
    "            if ch == ')' and generated.count('(') == generated.count(')'):\n",
    "                break\n",
    "    \n",
    "    return \"\".join(generated)\n",
    "\n",
    "def check_validity(sequence):\n",
    "    \"\"\"Check if a parenthesis sequence is valid (balanced).\"\"\"\n",
    "    depth = 0\n",
    "    for ch in sequence:\n",
    "        if ch == '(':\n",
    "            depth += 1\n",
    "        elif ch == ')':\n",
    "            depth -= 1\n",
    "            if depth < 0:\n",
    "                return False\n",
    "    return depth == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2215451/87601831.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for TinyGPT:\n\tUnexpected key(s) in state_dict: \"q_head.weight\", \"q_head.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[101]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m device = \u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model, stoi, itos, cfg = \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Custom input\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# print(\"\\n--- Custom Input Mode ---\")\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# user_input = \"[([()])\"\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_dyck_parens\u001b[39m(s: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[100]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mload_checkpoint\u001b[39m\u001b[34m(checkpoint_path, device)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Create model\u001b[39;00m\n\u001b[32m     24\u001b[39m model = TinyGPT(\n\u001b[32m     25\u001b[39m     vocab_size=vocab_size,\n\u001b[32m     26\u001b[39m     block_size=cfg.block_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     attn_pdrop=\u001b[32m0.0\u001b[39m\n\u001b[32m     33\u001b[39m ).to(device)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel_state_dict\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m model.eval()\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# print(f\"✓ Successfully loaded checkpoint from iteration {iteration}\")\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# print(f\"✓ Model config: vocab_size={vocab_size}, block_size={cfg.block_size}\")\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# print(f\"  n_layer={cfg.n_layer}, n_head={cfg.n_head}, n_embd={cfg.n_embd}\")\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# print(f\"✓ Training objective: {cfg.objective}\\n\")\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nfs/shuozhe/miniconda3/envs/xr1/lib/python3.11/site-packages/torch/nn/modules/module.py:2584\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2576\u001b[39m         error_msgs.insert(\n\u001b[32m   2577\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2578\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2579\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2580\u001b[39m             ),\n\u001b[32m   2581\u001b[39m         )\n\u001b[32m   2583\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2584\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2585\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2586\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2587\u001b[39m         )\n\u001b[32m   2588\u001b[39m     )\n\u001b[32m   2589\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for TinyGPT:\n\tUnexpected key(s) in state_dict: \"q_head.weight\", \"q_head.bias\". "
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "checkpoint_path = \"/nfs/shuozhe/clean_pretrain/tiny_llm_checkpoints/checkpoint_iter_3600.pt\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load model\n",
    "model, stoi, itos, cfg = load_checkpoint(checkpoint_path, device=device)\n",
    "\n",
    "# Custom input\n",
    "# print(\"\\n--- Custom Input Mode ---\")\n",
    "# user_input = \"[([()])\"\n",
    "\n",
    "\n",
    "\n",
    "def is_dyck_parens(s: str) -> bool:\n",
    "    \"\"\"\n",
    "    Return True iff the parentheses subsequence of `s` is a valid Dyck word.\n",
    "\n",
    "    Examples:\n",
    "        is_dyck_parens(\"a(b)c\")          -> True   (paren subseq: \"()\")\n",
    "        is_dyck_parens(\"ab)cd(\")         -> False  (\")(\" -> invalid)\n",
    "        is_dyck_parens(\"((x) y) z\")      -> True   (\"(())\")\n",
    "        is_dyck_parens(\"(()\")            -> False  (\"(()\" -> depth ends 1)\n",
    "        is_dyck_parens(\"no parens\")      -> True   (empty subseq is valid)\n",
    "    \"\"\"\n",
    "    depth = 0\n",
    "    for ch in s:\n",
    "        if ch == '(':\n",
    "            depth += 1\n",
    "        elif ch == ')':\n",
    "            depth -= 1\n",
    "            if depth < 0:\n",
    "                return False\n",
    "    return depth == 0\n",
    "\n",
    "user_input = \"((((ab0(\"\n",
    "\n",
    "# Generate\n",
    "temperature = 1\n",
    "temp = float(temperature) if temperature else 1.0\n",
    "\n",
    "output = generate_continuation(\n",
    "    model, user_input, stoi, itos,\n",
    "    max_new_tokens=150,\n",
    "    device=device,\n",
    "    temperature=temp\n",
    ")\n",
    "\n",
    "print(f\"Input:    {user_input}\")\n",
    "print(f\"Output:   {output}\")\n",
    "print(f\"Validity: {check_validity(output)}\")\n",
    "# print(is_dyck_parens(output))\n",
    "\n",
    "# ((((()(()()))())))\n",
    "\n",
    "# (((()())())(()())((()())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''                           -> True (expected True)\n",
      "'abc'                        -> True (expected True)\n",
      "'()'                         -> True (expected True)\n",
      "'(a)b'                       -> True (expected True)\n",
      "'a(b(c)d)e'                  -> True (expected True)\n",
      "'((x)y)z'                    -> True (expected True)\n",
      "'ab)cd('                     -> False (expected False)\n",
      "'(()'                        -> False (expected False)\n",
      "'())('                       -> False (expected False)\n",
      "'x)('                        -> False (expected False)\n",
      "'(((foo)))bar'               -> True (expected True)\n",
      "'foo(bar(baz)qux))'          -> False (expected False)\n",
      "All tests passed.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Validate Dyck-1 (parentheses) in a string while ignoring all other characters.\n",
    "\n",
    "Definition: Keep only '(' and ')' from the input. The string is valid iff\n",
    "the resulting sequence is a well-formed Dyck word: the running depth never\n",
    "goes negative and ends at zero.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "def is_dyck_parens(s: str) -> bool:\n",
    "    \"\"\"\n",
    "    Return True iff the parentheses subsequence of `s` is a valid Dyck word.\n",
    "\n",
    "    Examples:\n",
    "        is_dyck_parens(\"a(b)c\")          -> True   (paren subseq: \"()\")\n",
    "        is_dyck_parens(\"ab)cd(\")         -> False  (\")(\" -> invalid)\n",
    "        is_dyck_parens(\"((x) y) z\")      -> True   (\"(())\")\n",
    "        is_dyck_parens(\"(()\")            -> False  (\"(()\" -> depth ends 1)\n",
    "        is_dyck_parens(\"no parens\")      -> True   (empty subseq is valid)\n",
    "    \"\"\"\n",
    "    depth = 0\n",
    "    for ch in s:\n",
    "        if ch == '(':\n",
    "            depth += 1\n",
    "        elif ch == ')':\n",
    "            depth -= 1\n",
    "            if depth < 0:\n",
    "                return False\n",
    "    return depth == 0\n",
    "\n",
    "\n",
    "# Optional: a debugging variant that also reports the first error position.\n",
    "def check_dyck_parens(s: str) -> Tuple[bool, Optional[int], int]:\n",
    "    \"\"\"\n",
    "    Returns (valid, first_error_index, final_depth).\n",
    "\n",
    "    - valid: True iff the parentheses subsequence is Dyck-valid.\n",
    "    - first_error_index: index in the *original string* of the first place\n",
    "      where validity is violated (None if no violation).\n",
    "    - final_depth: depth after consuming the whole string (0 iff balanced).\n",
    "    \"\"\"\n",
    "    depth = 0\n",
    "    for i, ch in enumerate(s):\n",
    "        if ch == '(':\n",
    "            depth += 1\n",
    "        elif ch == ')':\n",
    "            depth -= 1\n",
    "            if depth < 0:\n",
    "                return False, i, depth\n",
    "    # If depth != 0, it's unbalanced (too many '('). No single error index,\n",
    "    # but caller can infer imbalance from final_depth.\n",
    "    return depth == 0, None if depth == 0 else None, depth\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tests = {\n",
    "        \"\": True,\n",
    "        \"abc\": True,\n",
    "        \"()\": True,\n",
    "        \"(a)b\": True,\n",
    "        \"a(b(c)d)e\": True,\n",
    "        \"((x)y)z\": True,\n",
    "        \"ab)cd(\": False,\n",
    "        \"(()\": False,\n",
    "        \"())(\": False,\n",
    "        \"x)(\": False,\n",
    "        \"(((foo)))bar\": True,\n",
    "        \"foo(bar(baz)qux))\": False,\n",
    "    }\n",
    "    for s, expected in tests.items():\n",
    "        got = is_dyck_parens(s)\n",
    "        print(f\"{s!r:28} -> {got} (expected {expected})\")\n",
    "        assert got == expected, f\"Mismatch for {s!r}\"\n",
    "    print(\"All tests passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((()())))(())((()))\n",
      "(()(()()()()(())))\n",
      "()()(()((()())))()\n",
      "()((())())(((())))\n",
      "()()((()()))()()()\n",
      "(()(((()))()(()())))\n",
      "()(())(((())))\n",
      "(())(((((())))))\n",
      "(())((()))\n",
      "()()(()())((()))\n"
     ]
    }
   ],
   "source": [
    "def make_paren_code(n_sequences=50000, min_len=20, max_len=200, emit_key=False):\n",
    "    \"\"\"Paren-code language with 2 hidden keys (0/1) that bias parity of opens vs closes.\n",
    "    If emit_key=True, each line is prefixed with '0:' or '1:' so the key is observable.\n",
    "    Sequences are exact-length (even L >= 2) and balanced.\n",
    "    \"\"\"\n",
    "    def gen_one(L):\n",
    "        if L % 2 == 1 or L < 2:\n",
    "            L = max(2, L + (L % 2))\n",
    "        key = random.choice('01')\n",
    "        s = []\n",
    "        depth = 0\n",
    "        for t in range(L):\n",
    "            rem = L - t\n",
    "            if depth == rem:\n",
    "                s.append(')'); depth -= 1\n",
    "                continue\n",
    "            if depth == 0:\n",
    "                s.append('('); depth += 1\n",
    "                continue\n",
    "            even = (depth % 2 == 0)\n",
    "            # parity preference flipped by key\n",
    "            ch = '(' if (key == '0' and even) or (key == '1' and not even) else ')'\n",
    "            # feasibility guardrails\n",
    "            if ch == '(' and depth + 1 > rem - 1:\n",
    "                ch = ')'\n",
    "            if ch == ')' and depth == 0:\n",
    "                ch = '('\n",
    "            s.append(ch)\n",
    "            depth += 1 if ch == '(' else -1\n",
    "        assert depth == 0 and len(s) == L\n",
    "        body = \"\".join(s)\n",
    "        return (key + \":\" + body) if emit_key else body\n",
    "    return \"\\n\".join(gen_one(random.randint(min_len, max_len)) for _ in range(n_sequences))\n",
    "\n",
    "def make_dyck1_greedy(n_sequences=50000, min_len=20, max_len=200):\n",
    "    \"\"\"Greedy exact-length baseline: emit k='(' then k=')' for exact-length L (L even).\n",
    "    This produces highly-structured baseline sequences like '(((...)))'.\n",
    "    \"\"\"\n",
    "    def gen_one(L):\n",
    "        if L % 2 == 1 or L < 2:\n",
    "            L = max(2, L + (L % 2))\n",
    "        k = L // 2\n",
    "        return \"(\" * k + \")\" * k\n",
    "    seqs = []\n",
    "    for _ in range(n_sequences):\n",
    "        L = random.randint(min_len, max_len)\n",
    "        seqs.append(gen_one(L))\n",
    "    return \"\\n\".join(seqs)\n",
    "\n",
    "def make_dyck1_random(n_sequences=50000, min_len=20, max_len=200):\n",
    "    \"\"\"Exact-length Dyck-1 sequences. Ensures each returned sequence has exact length L (even),\n",
    "    never drops below depth 0 and ends at depth 0.\n",
    "    Uses a simple random feasible-walk sampler (not perfectly uniform over all Dyck words of length L,\n",
    "    but avoids length drift and infeasible moves).\n",
    "    \"\"\"\n",
    "    def gen_one(L):\n",
    "        # ensure even length >= 2\n",
    "        if L % 2 == 1 or L < 2:\n",
    "            L = max(2, L + (L % 2))\n",
    "        s = []\n",
    "        depth = 0\n",
    "        for t in range(L):\n",
    "            rem = L - t\n",
    "            # if we must close to reach zero in remaining steps\n",
    "            if depth == rem:\n",
    "                s.append(')')\n",
    "                depth -= 1\n",
    "                continue\n",
    "            if depth == 0:\n",
    "                s.append('(')\n",
    "                depth += 1\n",
    "                continue\n",
    "            # both moves feasible; avoid opening when not enough remaining steps to close later\n",
    "            can_open = (depth + 1) <= (rem - 1)\n",
    "            if can_open and random.random() < 0.5:\n",
    "                s.append('(')\n",
    "                depth += 1\n",
    "            else:\n",
    "                s.append(')')\n",
    "                depth -= 1\n",
    "        assert depth == 0 and len(s) == L\n",
    "        return \"\".join(s)\n",
    "    return \"\\n\".join(gen_one(random.randint(min_len, max_len)) for _ in range(n_sequences))\n",
    "\n",
    "def make_copy_dataset(n_sequences=50000, min_len=5, max_len=40, alphabet=\"abcd\"):\n",
    "    seqs = []\n",
    "    for _ in range(n_sequences):\n",
    "        L = random.randint(min_len, max_len)\n",
    "        x = \"\".join(random.choice(alphabet) for _ in range(L))\n",
    "        seqs.append(\"<s>\" + x + \"#\" + x + \"</s>\")\n",
    "    return \"\\n\".join(seqs)\n",
    "\n",
    "xx = make_dyck1_random(n_sequences=10, min_len=10, max_len=20)\n",
    "print(xx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2215451/1591555061.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TINYGPT CHECKPOINT TESTER\n",
      "================================================================================\n",
      "\n",
      "Loading checkpoint from: /nfs/shuozhe/clean_pretrain/checkpoints/checkpoint_iter_2000.pt\n",
      "✓ Successfully loaded checkpoint from iteration 2000\n",
      "✓ Model config: vocab_size=5, block_size=256\n",
      "  n_layer=4, n_head=4, n_embd=256\n",
      "✓ Training objective: acc_pg\n",
      "\n",
      "\n",
      "================================================================================\n",
      "OPTIONS:\n",
      "  1. Enter custom input\n",
      "  2. Use dyck_random example\n",
      "  3. Quit\n",
      "================================================================================\n",
      "\n",
      "--- Custom Input Mode ---\n",
      "\n",
      "================================================================================\n",
      "INPUT: ((\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "MODEL OUTPUT:\n",
      "================================================================================\n",
      "(()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()(\n",
      "\n",
      "================================================================================\n",
      "Analysis:\n",
      "  Length: 152\n",
      "  Valid (balanced parens): False\n",
      "================================================================================\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Configuration\n",
    "    checkpoint_path = \"/nfs/shuozhe/clean_pretrain/checkpoints/checkpoint_iter_2000.pt\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"TINYGPT CHECKPOINT TESTER\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    # Load model\n",
    "    model, stoi, itos, cfg = load_checkpoint(checkpoint_path, device=device)\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"OPTIONS:\")\n",
    "        print(\"  1. Enter custom input\")\n",
    "        print(\"  2. Use dyck_random example\")\n",
    "        print(\"  3. Quit\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        choice = input(\"\\nYour choice (1/2/3): \").strip()\n",
    "        \n",
    "        if choice == '3':\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "        \n",
    "        elif choice == '1':\n",
    "            # Custom input\n",
    "            print(\"\\n--- Custom Input Mode ---\")\n",
    "            user_input = input(\"Enter your input prompt: \").strip()\n",
    "            \n",
    "            if not user_input:\n",
    "                print(\"Empty input, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"INPUT: {user_input}\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "            # Generate\n",
    "            temperature = input(\"Temperature (default 1.0, press Enter to use default): \").strip()\n",
    "            temp = float(temperature) if temperature else 1.0\n",
    "            \n",
    "            output = generate_continuation(\n",
    "                model, user_input, stoi, itos,\n",
    "                max_new_tokens=150,\n",
    "                device=device,\n",
    "                temperature=temp\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"MODEL OUTPUT:\")\n",
    "            print(f\"{'='*80}\")\n",
    "            print(output)\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"Analysis:\")\n",
    "            print(f\"  Length: {len(output)}\")\n",
    "            print(f\"  Valid (balanced parens): {check_validity(output)}\")\n",
    "            print(f\"{'='*80}\")\n",
    "        \n",
    "        elif choice == '2':\n",
    "            # Dyck random example\n",
    "            print(\"\\n--- Dyck Random Mode ---\")\n",
    "            \n",
    "            # Generate a dyck_random sequence\n",
    "            dyck_samples = make_dyck1_random(n_sequences=1, min_len=30, max_len=80)\n",
    "            full_sequence = dyck_samples.strip()\n",
    "            \n",
    "            # Use first few characters as prompt\n",
    "            prompt_len = min(5, len(full_sequence))\n",
    "            prompt = full_sequence[:prompt_len]\n",
    "            \n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"GROUND TRUTH (full dyck_random sequence):\")\n",
    "            print(f\"{'='*80}\")\n",
    "            print(full_sequence)\n",
    "            print(f\"\\nLength: {len(full_sequence)}, Valid: {check_validity(full_sequence)}\")\n",
    "            \n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"INPUT (first {prompt_len} characters as prompt):\")\n",
    "            print(f\"{'='*80}\")\n",
    "            print(prompt)\n",
    "            \n",
    "            # Generate continuation\n",
    "            temperature = input(\"\\nTemperature (default 1.0, press Enter to use default): \").strip()\n",
    "            temp = float(temperature) if temperature else 1.0\n",
    "            \n",
    "            output = generate_continuation(\n",
    "                model, prompt, stoi, itos,\n",
    "                max_new_tokens=len(full_sequence),\n",
    "                device=device,\n",
    "                temperature=temp\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"MODEL OUTPUT:\")\n",
    "            print(f\"{'='*80}\")\n",
    "            print(output)\n",
    "            \n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"COMPARISON:\")\n",
    "            print(f\"{'='*80}\")\n",
    "            print(f\"Ground truth length: {len(full_sequence)}\")\n",
    "            print(f\"Generated length:    {len(output)}\")\n",
    "            print(f\"Ground truth valid:  {check_validity(full_sequence)}\")\n",
    "            print(f\"Generated valid:     {check_validity(output)}\")\n",
    "            print(f\"{'='*80}\")\n",
    "        \n",
    "        else:\n",
    "            print(\"Invalid choice, please try again.\")\n",
    "        \n",
    "        # Ask if user wants to continue\n",
    "        cont = input(\"\\nTest another input? (y/n): \").strip().lower()\n",
    "        if cont != 'y':\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
